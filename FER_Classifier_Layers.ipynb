{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# All the code lines in this cell are taken from Reference [4]\n\nimport torch\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data.dataloader import DataLoader\n\n\n# train and validation data directory\ntrain_data_dir = \"images/images/train/\"\nvalidation_data_dir = \"images/images/validation/\"\n\n\n# load the train and validation data\ntrain_dataset = ImageFolder(train_data_dir,transform = transforms.Compose([\n                transforms.ToTensor()\n]))\nvalidation_dataset = ImageFolder(validation_data_dir,transforms.Compose([\n                transforms.ToTensor()\n]))\n\n\n# load the train and validation into batches.\ntrain_dl = DataLoader(train_dataset, batch_size = 128, shuffle = True, num_workers = 4)\n\n# Few changes (batch_size, shuffle = False) were made to val_dl object by referring to Reference[1]\nval_dl = DataLoader(validation_dataset, batch_size = 128, shuffle = False, num_workers = 4)\n\n# All the code lines in this cell are taken from Reference [1]\n\nimport torch.nn as nn # basic building block for neural networks\nimport torch.nn.functional as F # import convolution functions like Relu\n\nclass Net(nn.Module):\n# Models a simple Convolutional Neural Network\n\t\n    def __init__(self):\n# initialize the network \n        super(Net, self).__init__() \n\n# The parameters of Conv2d and Linear layers are modified slightly from the original code.\n\n# 3x3 square convolution kernel\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n    \n# Max pooling over a (2, 2) window\n        self.pool = nn.MaxPool2d(2, 2)\n         \n        self.fc1 = nn.Linear(64 * 10 * 10, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 7)\n\n    def forward(self, x):\n# the forward propagation algorithm\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n\n# The parameters of view are modified slightly from the original code.        \n        x = x.view(-1, 64 * 10 * 10)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nprint(net)\n\n# All the code lines in this cell are taken from Reference [1]\n\nimport torch.optim as optim # optimizer\n\ncriterion = nn.CrossEntropyLoss()\n\n# 'lr' value is modified from the original code.\noptimizer = optim.SGD(net.parameters(), lr = 0.01, momentum = 0.9)\n\n# The below code lines are taken from Reference [1]\ntrain_losses=[]\ntrain_accu=[]\n\n# 'Number of epochs'is modified from the original code.\nfor epoch in range(10):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    total = 0\n    correct = 0\n    for i, data in enumerate(train_dl, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n# The below code lines are taken from Reference [5]\n        running_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n       \n        train_loss=running_loss/len(train_dl)\n        accu=100.*correct/total\n   \n        train_accu.append(accu)\n        train_losses.append(train_loss)\n        \nprint('\\nLoss for train dataset : %.3f | Accuracy for train dataset : %.3f'%(train_loss,accu))\n\n# The below code lines are taken from Reference [1]\n# 'Number of epochs' is modified from the original code.\n\nfor epoch in range(10):\n    \n    eval_losses=[]\n    eval_accu=[]\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in val_dl:\n            images, labels = data\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n# The below code lines are taken from Reference [5]\n            test_loss=running_loss/len(val_dl)\n            accu=100.*correct/total\n            \n            eval_losses.append(test_loss)\n            eval_accu.append(accu)\n\nprint('\\nLoss for validation dataset : %.3f | Accuracy for validation dataset : %.3f'%(test_loss,accu))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}