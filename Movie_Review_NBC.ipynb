{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LakshmiMedapati96/DM-Kaggle_Image_Classification/blob/main/Movie_Review_NBC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries and Loading the dataset**"
      ],
      "metadata": {
        "_uuid": "b623e5e0-65fa-4d97-a280-c41c8c99486c",
        "_cell_guid": "a50ee976-da20-4466-b51e-b8edc528c103",
        "trusted": true,
        "id": "Qc-PwBVW7jRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The \"encoding='latin-1'\" in the below line of code were taken from Reference [1].\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import defaultdict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"rt_reviews.csv\", encoding='latin-1')\n",
        "data.head()"
      ],
      "metadata": {
        "_uuid": "94f39670-b2fd-41ec-9c3f-0cff9f6eff5a",
        "_cell_guid": "271f5e04-44c1-49ce-b113-43c14b592f66",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:12:47.912389Z",
          "iopub.execute_input": "2023-04-16T14:12:47.912868Z",
          "iopub.status.idle": "2023-04-16T14:12:51.523161Z",
          "shell.execute_reply.started": "2023-04-16T14:12:47.912828Z",
          "shell.execute_reply": "2023-04-16T14:12:51.521432Z"
        },
        "trusted": true,
        "id": "5UBme7CM7jRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Cleaning**"
      ],
      "metadata": {
        "_uuid": "1d70888a-203a-4ad6-bb01-4876e1a71755",
        "_cell_guid": "307f0176-e2aa-416c-9017-60583091b874",
        "trusted": true,
        "id": "oglq-Q4Z7jRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [3].\n",
        "\n",
        "# Define function for removing square brackets and special characters\n",
        "def remove_square_brackets_special_characters(text):\n",
        "    text = re.sub('\\[[^]]*\\]','', text)\n",
        "    text = re.sub(r'[^a-zA-z0-9\\s]','',text)\n",
        "    return text\n",
        "\n",
        "# Apply function on review column\n",
        "data['Review'] = data['Review'].apply(remove_square_brackets_special_characters)\n",
        "\n",
        "# data.head()\n",
        "data.shape"
      ],
      "metadata": {
        "_uuid": "cdae3b4f-6ac0-45f7-98cd-29282e7bd29c",
        "_cell_guid": "b878fef9-8063-42bb-8433-9dadaf5255f7",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:12:51.525569Z",
          "iopub.execute_input": "2023-04-16T14:12:51.526879Z",
          "iopub.status.idle": "2023-04-16T14:12:53.708475Z",
          "shell.execute_reply.started": "2023-04-16T14:12:51.526816Z",
          "shell.execute_reply": "2023-04-16T14:12:53.706892Z"
        },
        "trusted": true,
        "id": "j8s3KSJZ7jRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dividing the dataset into Train, Development and Test sets (60:20:20)**"
      ],
      "metadata": {
        "_uuid": "887523a9-7584-40e8-b5bb-c57eb3b6d802",
        "_cell_guid": "6bad3db1-a48d-4a82-8dcf-f8e941102bfa",
        "trusted": true,
        "id": "RD1lqlgJ7jRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me by referring to Reference [2].\n",
        "\n",
        "# Split the data into training and remaining datasets\n",
        "trainset, remset = train_test_split(data, train_size = 0.6)\n",
        "\n",
        "# Split the remaining dataset into development and test datasets\n",
        "devset, testset = train_test_split(remset, train_size = 0.5)\n",
        "\n",
        "trainset.shape, devset.shape, testset.shape"
      ],
      "metadata": {
        "_uuid": "c77d37b6-63c4-4b1d-855a-6ab2c45de15a",
        "_cell_guid": "2a2549fd-5b87-4dd3-b351-47b43e9123c0",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:12:53.709615Z",
          "iopub.execute_input": "2023-04-16T14:12:53.709924Z",
          "iopub.status.idle": "2023-04-16T14:12:53.867076Z",
          "shell.execute_reply.started": "2023-04-16T14:12:53.709891Z",
          "shell.execute_reply": "2023-04-16T14:12:53.865716Z"
        },
        "trusted": true,
        "id": "okw0NK4N7jRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build vocabulary as dictionary**"
      ],
      "metadata": {
        "id": "P5I9IkZwhc_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me.\n",
        "\n",
        "# Defining a function to build vocabulary as dictionary and \n",
        "# omitting rare words (if the occurrence is less than five times)\n",
        "def build_vocab_dict(dataset, flag=False):\n",
        "    vocab_dict = {}\n",
        "    for review in dataset[\"Review\"]:\n",
        "        review = review.split(\" \")\n",
        "        # print(review)\n",
        "        for word in review:\n",
        "            word = word.lower()\n",
        "            if word in vocab_dict:\n",
        "                vocab_dict[word] += 1\n",
        "            else:\n",
        "                vocab_dict[word] = 1\n",
        "    vocab_dict.pop('')                                     # for removing '' in the dictionary\n",
        "    if flag:\n",
        "        return vocab_dict\n",
        "    total_vocab_dict = {k: v for k, v in vocab_dict.items() if v >= 5}\n",
        "#print(str(total_word_dict)[:1000] + \"...........\")\n",
        "    return total_vocab_dict"
      ],
      "metadata": {
        "_uuid": "9f8a273e-0f64-4f9c-9900-daae7809be62",
        "_cell_guid": "35f2e4a8-266f-4c2e-be8b-80f2cfc38724",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:12:53.869873Z",
          "iopub.execute_input": "2023-04-16T14:12:53.870210Z",
          "iopub.status.idle": "2023-04-16T14:12:53.878875Z",
          "shell.execute_reply.started": "2023-04-16T14:12:53.870181Z",
          "shell.execute_reply": "2023-04-16T14:12:53.877770Z"
        },
        "trusted": true,
        "id": "d6D5bW_q7jRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Total words dictionary - Entire dataset and Training data**"
      ],
      "metadata": {
        "_uuid": "9c732346-88e0-48dd-8380-aaf77f4d6cd7",
        "_cell_guid": "53c4fe08-0656-4bbc-b89a-c06224273e33",
        "trusted": true,
        "id": "3QrCzE8G7jRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me.\n",
        "\n",
        "total_word_dict = build_vocab_dict(data)                        # dictionary for entire dataset\n",
        "\n",
        "total_word_dict_train = build_vocab_dict(trainset)              # dictionary for training dataset\n",
        "print(f\"Total words in the dictionary (train set): {total_word_dict_train}\")"
      ],
      "metadata": {
        "_uuid": "c5d9c040-bcb2-4aca-b4ca-c978ae6a82bf",
        "_cell_guid": "99139c30-99b0-4e76-8092-8f79ee6034b3",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:12:53.879851Z",
          "iopub.execute_input": "2023-04-16T14:12:53.880179Z",
          "iopub.status.idle": "2023-04-16T14:13:01.055515Z",
          "shell.execute_reply.started": "2023-04-16T14:12:53.880147Z",
          "shell.execute_reply": "2023-04-16T14:13:01.054312Z"
        },
        "trusted": true,
        "id": "9n_8Liju7jRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating prior probabilities**"
      ],
      "metadata": {
        "_uuid": "01da8877-65f1-46a2-ab7d-41fa08e2bf1b",
        "_cell_guid": "802610da-1023-46b6-b2e3-7af1d8935342",
        "trusted": true,
        "id": "vtdZFDJP7jRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me.\n",
        "\n",
        "# Creating separate dataframes for fresh and rotten datasets\n",
        "fresh_df = trainset[trainset[\"Freshness\"] == 'fresh']\n",
        "rotten_df = trainset[trainset[\"Freshness\"] == 'rotten']\n",
        "#print(fresh_df)\n",
        "#print(rotten_df)\n",
        "\n",
        "# Probabilities for fresh and rotten classes\n",
        "prob_fresh = fresh_df.shape[0]  / (fresh_df.shape[0] + rotten_df.shape[0])\n",
        "prob_rotten = rotten_df.shape[0]  / (fresh_df.shape[0] + rotten_df.shape[0])\n",
        "\n",
        "print(f\"P(rotten) = {str(prob_rotten)}\")\n",
        "print(f\"P(fresh) = {str(prob_fresh)}\")"
      ],
      "metadata": {
        "_uuid": "9f0d122d-3d48-46ac-a782-39c0a667ce3c",
        "_cell_guid": "f5e0f82f-74cb-421b-85be-bf8d63421155",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:01.056734Z",
          "iopub.execute_input": "2023-04-16T14:13:01.057043Z",
          "iopub.status.idle": "2023-04-16T14:13:01.123745Z",
          "shell.execute_reply.started": "2023-04-16T14:13:01.057011Z",
          "shell.execute_reply": "2023-04-16T14:13:01.122324Z"
        },
        "trusted": true,
        "id": "UkeSsC2W7jRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating separate word dictionaries for fresh and rotten classes**"
      ],
      "metadata": {
        "_uuid": "6c8a20c5-8aa3-48b5-b033-7e1882db48b7",
        "_cell_guid": "1c134626-b851-43c4-86a4-d485aabc34a3",
        "trusted": true,
        "id": "Ui8J6IbP7jRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me.\n",
        "\n",
        "# fresh word dictionary\n",
        "fresh_word_dict_train = build_vocab_dict(fresh_df)\n",
        "print(f\"Words dictionary for fresh label: {fresh_word_dict_train}\")\n",
        "\n",
        "# rotten word dictionary\n",
        "rotten_word_dict_train = build_vocab_dict(rotten_df)\n",
        "print(f\"Words dictionary for rotten label: {rotten_word_dict_train}\")"
      ],
      "metadata": {
        "_uuid": "aa616c50-ed97-4c7f-bc0c-1ced5df8ac82",
        "_cell_guid": "661b6dca-509a-43e3-b90c-62b4e176de89",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:01.125736Z",
          "iopub.execute_input": "2023-04-16T14:13:01.126156Z",
          "iopub.status.idle": "2023-04-16T14:13:03.829698Z",
          "shell.execute_reply.started": "2023-04-16T14:13:01.126113Z",
          "shell.execute_reply": "2023-04-16T14:13:03.827820Z"
        },
        "trusted": true,
        "id": "F653Kyk07jRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating probability of the occurrence**"
      ],
      "metadata": {
        "_uuid": "165f8822-e5f3-4fea-b817-25045c2f2304",
        "_cell_guid": "10679010-9015-4e35-8d3d-1ad23a88dfae",
        "trusted": true,
        "id": "6Q_kRcAZ7jRj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me.\n",
        "\n",
        "# Calculating probability of all the words\n",
        "total_num_of_words_train = sum(list(total_word_dict_train.values()))\n",
        "\n",
        "for key, value in total_word_dict_train.items():\n",
        "    total_word_dict_train[key] = (value, value*100/total_num_of_words_train)\n",
        "print(f\"Probability of the occurence: {str(total_word_dict_train)}\")"
      ],
      "metadata": {
        "_uuid": "f2357abe-7247-4e68-b058-48fb3742ffaa",
        "_cell_guid": "c5ccfba8-0ec4-49bb-9743-92dda2644729",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:03.831750Z",
          "iopub.execute_input": "2023-04-16T14:13:03.832276Z",
          "iopub.status.idle": "2023-04-16T14:13:03.971533Z",
          "shell.execute_reply.started": "2023-04-16T14:13:03.832227Z",
          "shell.execute_reply": "2023-04-16T14:13:03.970279Z"
        },
        "trusted": true,
        "id": "60OJYqy87jRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating conditional probability based on the sentiment**"
      ],
      "metadata": {
        "id": "xE_oZMmGjxG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me.\n",
        "\n",
        "# Calculating probability of each word in fresh.\n",
        "fresh_total_num_of_words = sum(list(fresh_word_dict_train.values()))\n",
        "fresh_word_prob_dict_train = {}\n",
        "for key, value in fresh_word_dict_train.items():\n",
        "    fresh_word_prob_dict_train[key] = value*100/fresh_total_num_of_words\n",
        "print(f\"Conditional probability based on 'fresh' label: {str(fresh_word_prob_dict_train)}\")\n",
        "\n",
        "# Calculating probability of each word in rotten.\n",
        "rotten_total_num_of_words = sum(list(rotten_word_dict_train.values()))\n",
        "rotten_word_prob_dict_train = {}\n",
        "for key, value in rotten_word_dict_train.items():\n",
        "    rotten_word_prob_dict_train[key] = value*100/rotten_total_num_of_words\n",
        "print(f\"Conditional probability based on 'rotten' label: {str(rotten_word_prob_dict_train)}\")"
      ],
      "metadata": {
        "id": "_wCbQdiHjQ1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating accuracy on Development dataset**"
      ],
      "metadata": {
        "id": "hWanmNIFkhCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [4].\n",
        "\n",
        "# Defining a function to calculate accuracy score\n",
        "def accuracyscore(actual, predicted):\n",
        "    correct = 0\n",
        "    for i in range(len(actual)):\n",
        "        if actual[i] == \"rotten\":\n",
        "            value = 0\n",
        "        else:\n",
        "            value = 1\n",
        "        if value == predicted[i]:\n",
        "            correct = correct + 1\n",
        "            \n",
        "        # print(actual[i] , predicted[i])\n",
        "    #print(f\"correct = {correct}\")\n",
        "    #print(str(rotten_word_prob_dict_train)[:200])\n",
        "    return correct * 100.0/ float(len(actual))"
      ],
      "metadata": {
        "_uuid": "7877b597-a340-4e55-8a0d-b09af2db2502",
        "_cell_guid": "55853aa0-b3a8-426a-8635-a9c2299f30a1",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:03.972656Z",
          "iopub.execute_input": "2023-04-16T14:13:03.972931Z",
          "iopub.status.idle": "2023-04-16T14:13:03.979849Z",
          "shell.execute_reply.started": "2023-04-16T14:13:03.972905Z",
          "shell.execute_reply": "2023-04-16T14:13:03.978677Z"
        },
        "trusted": true,
        "id": "9wooG9pT7jRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [4].\n",
        "\n",
        "# Defining a function to predict the class label\n",
        "def predict(preddata):\n",
        "    pred = []\n",
        "    for review in preddata[\"Review\"]:\n",
        "        vocab_dict = {}\n",
        "        review = review.split(\" \")\n",
        "        # print(review)\n",
        "        for word in review:\n",
        "            word = word.lower()\n",
        "            if word in vocab_dict:\n",
        "                vocab_dict[word] += 1\n",
        "            else:\n",
        "                vocab_dict[word] = 1\n",
        "        vocab_dict.pop('', None)                                     # for removing '' in the dictionary\n",
        "        likelihood_rotten = 1.0\n",
        "        likelihood_fresh = 1.0\n",
        "        \n",
        "        for word in vocab_dict:\n",
        "            if not word in rotten_word_prob_dict_train:\n",
        "                rotten_word_prob_dict_train[word] = 0.0\n",
        "\n",
        "            if not word in fresh_word_prob_dict_train:\n",
        "                fresh_word_prob_dict_train[word] = 0.0\n",
        "\n",
        "            likelihood_rotten = likelihood_rotten * rotten_word_prob_dict_train[word]\n",
        "            likelihood_fresh = likelihood_fresh * fresh_word_prob_dict_train[word]\n",
        "        \n",
        "        posterior_rotten = prob_rotten * likelihood_rotten\n",
        "        posterior_fresh = prob_fresh * likelihood_fresh\n",
        "\n",
        "        if posterior_rotten > posterior_fresh:\n",
        "            y_pred = 0\n",
        "        else:\n",
        "            y_pred = 1\n",
        "\n",
        "        pred.append(y_pred)\n",
        "    return pred"
      ],
      "metadata": {
        "_uuid": "e4f5e050-47af-4152-bb9f-8c35eaf4dc6a",
        "_cell_guid": "9fe25cf2-444d-47f8-856f-2d9f3e5be308",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:03.982624Z",
          "iopub.execute_input": "2023-04-16T14:13:03.982958Z",
          "iopub.status.idle": "2023-04-16T14:13:03.993069Z",
          "shell.execute_reply.started": "2023-04-16T14:13:03.982927Z",
          "shell.execute_reply": "2023-04-16T14:13:03.992216Z"
        },
        "trusted": true,
        "id": "XeCz2inp7jRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [4].\n",
        "\n",
        "dev_pred = predict(devset)\n",
        "\n",
        "accuracy = accuracyscore(devset['Freshness'].to_list(),dev_pred)\n",
        "print(f\"Accuracy on development set before smoothing : {accuracy}%\")"
      ],
      "metadata": {
        "_uuid": "0ec53fdd-193b-4941-903d-e65e3c578c66",
        "_cell_guid": "8bd44ddf-30d9-44cb-9b68-ee39ca5b0002",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:03.994895Z",
          "iopub.execute_input": "2023-04-16T14:13:03.995420Z",
          "iopub.status.idle": "2023-04-16T14:13:04.012797Z",
          "shell.execute_reply.started": "2023-04-16T14:13:03.995378Z",
          "shell.execute_reply": "2023-04-16T14:13:04.010958Z"
        },
        "trusted": true,
        "id": "-zZD0BFp7jRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying laplace smoothing**"
      ],
      "metadata": {
        "id": "POfkkiT6nNJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by referring to Reference [4].\n",
        "\n",
        "# Defining afunction to apply smoothing technique\n",
        "def laplace_smoothing(word_freq_0, word_freq_1, alpha, vocab_dict):\n",
        "    word_freq_0_probs = {}\n",
        "    word_freq_1_probs = {}\n",
        "\n",
        "    vocab_len = len(vocab_dict)\n",
        "    for word in vocab_dict:\n",
        "        word_freq_0_probs[word] = (word_freq_0.get(word, 0) + 1) / (len(word_freq_0) + vocab_len * alpha)\n",
        "        word_freq_1_probs[word] = (word_freq_1.get(word, 0) + 1) / (len(word_freq_1) + vocab_len * alpha)\n",
        "\n",
        "    return word_freq_0_probs, word_freq_1_probs"
      ],
      "metadata": {
        "_uuid": "fa4cabce-edcc-4a90-8abf-1fdd29e009a0",
        "_cell_guid": "c50754c2-d1a1-44ab-81bb-4a7516dfcf44",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:04.014233Z",
          "iopub.execute_input": "2023-04-16T14:13:04.014613Z",
          "iopub.status.idle": "2023-04-16T14:13:04.026517Z",
          "shell.execute_reply.started": "2023-04-16T14:13:04.014574Z",
          "shell.execute_reply": "2023-04-16T14:13:04.024519Z"
        },
        "trusted": true,
        "id": "RKp8x5Vd7jRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [4].\n",
        "\n",
        "# Defining a function to predict the class label with laplace smoothing\n",
        "def predict_alpha(preddata, alpha, rotten_word_prob_dict_train, fresh_word_prob_dict_train):\n",
        "    import time\n",
        "    #print(\"Alpha prediction started.\")\n",
        "    pred = []\n",
        "    i = 0\n",
        "    #print(\"Iter length : \", len(preddata))\n",
        "    for review in preddata[\"Review\"]:\n",
        "        # s_t = time.time()\n",
        "        i = i+1\n",
        "        #print(f\"Iter value: {i}\")\n",
        "        vocab_dict = {}\n",
        "        review = review.split(\" \")\n",
        "        # print(review)\n",
        "        # Create a defaultdict with int as the default factory\n",
        "        vocab_dict = defaultdict(int)\n",
        "        import time\n",
        "        # s_t_2 = time.time()\n",
        "        for word in review:\n",
        "            word = word.lower()\n",
        "            vocab_dict[word] += 1\n",
        "        vocab_dict.pop('', None)                                    # for removing '' in the dictionary\n",
        "        # a1_t = time.time()- s_t_2\n",
        "        # print(f\"time taken for word_review: {a1_t}sec\")\n",
        "        likelihood_rotten = 1.0\n",
        "        likelihood_fresh = 1.0\n",
        "        # s_t_3 = time.time()\n",
        "        for word in vocab_dict:\n",
        "            if not word in rotten_word_prob_dict_train:\n",
        "                rotten_word_prob_dict_train[word] = 0.0\n",
        "\n",
        "            if not word in fresh_word_prob_dict_train:\n",
        "                fresh_word_prob_dict_train[word] = 0.0\n",
        "            modified_rotten_word_prob_dict_train, modified_fresh_word_prob_dict_train = laplace_smoothing(rotten_word_prob_dict_train, fresh_word_prob_dict_train, alpha, vocab_dict)\n",
        "            likelihood_rotten = likelihood_rotten * modified_rotten_word_prob_dict_train[word]\n",
        "            likelihood_fresh = likelihood_fresh * modified_fresh_word_prob_dict_train[word]\n",
        "        # a_t = time.time()- s_t_3\n",
        "        # print(f\"total time taken for word_vocabdict: {a_t}sec\")\n",
        "        posterior_rotten = prob_rotten * likelihood_rotten\n",
        "        posterior_fresh = prob_fresh * likelihood_fresh\n",
        "\n",
        "        if posterior_rotten > posterior_fresh:\n",
        "            y_pred = 0\n",
        "        else:\n",
        "            y_pred = 1\n",
        "\n",
        "        pred.append(y_pred)\n",
        "        # print(\"appended.\")\n",
        "        # a_t = time.time()- s_t\n",
        "        # print(f\"total time taken for iter: {a_t}sec\")\n",
        "    return pred"
      ],
      "metadata": {
        "_uuid": "b277fec4-f509-4b29-ae93-748faf4620e3",
        "_cell_guid": "54ecff02-f31e-49ee-8c18-f283d3e34f5d",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:13:04.028617Z",
          "iopub.execute_input": "2023-04-16T14:13:04.028982Z",
          "iopub.status.idle": "2023-04-16T14:13:04.040920Z",
          "shell.execute_reply.started": "2023-04-16T14:13:04.028944Z",
          "shell.execute_reply": "2023-04-16T14:13:04.039186Z"
        },
        "trusted": true,
        "id": "NmBI_Hqm7jRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Determining the best value for alpha**"
      ],
      "metadata": {
        "id": "1M_QOliHnjaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [4].\n",
        "\n",
        "alpha_values = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
        "lap_acc = []\n",
        "# print(str(rotten_word_prob_dict_train)[:200])\n",
        "for alpha in alpha_values:\n",
        "  # print(\"alpha value:\", alpha)\n",
        "  alpha_preds = predict_alpha(devset, alpha, rotten_word_prob_dict_train, fresh_word_prob_dict_train)\n",
        "  # print(\"Alpha prediction ended.\")\n",
        "  alpha_accuracy = accuracyscore (devset[\"Freshness\"].to_list(), alpha_preds)\n",
        "  print(f'alpha = {alpha}, Accuracy = {alpha_accuracy} %')\n",
        "  lap_acc.append(alpha_accuracy)"
      ],
      "metadata": {
        "_uuid": "3a886c03-ad3e-40e4-a317-9a23bc52e219",
        "_cell_guid": "3d095f34-0fe5-43ca-8bf1-f247f24fbac3",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:20:45.343007Z",
          "iopub.execute_input": "2023-04-16T14:20:45.343515Z"
        },
        "trusted": true,
        "id": "XspnhR1y7jRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [4].\n",
        "\n",
        "plt.plot(alpha_values, lap_acc)\n",
        "plt.xlabel('alpha')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "_uuid": "3976d865-8725-47e7-a788-55730a71d276",
        "_cell_guid": "39009540-aadb-4950-80e1-c82a8eabf100",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "n0-gRHBI7jRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deriving the Top 10 words that predicts each class**"
      ],
      "metadata": {
        "id": "KhMWpYjApggX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were written by me.\n",
        "\n",
        "# Top 10 words - fresh\n",
        "sorted_fresh_train = sorted(fresh_word_dict_train.items(), key=lambda x: x[1], reverse=True)\n",
        "print(f\"Top 10 words that predicts 'fresh' class : {dict(sorted_fresh_train[:10])}\")\n",
        "\n",
        "# Top 10 words - rotten\n",
        "sorted_rotten_train = sorted(rotten_word_dict_train.items(), key=lambda x: x[1], reverse=True)\n",
        "print(f\"Top 10 words that predicts 'rotten' class : {dict(sorted_rotten_train[:10])}\")"
      ],
      "metadata": {
        "_uuid": "84ff925b-77a1-4864-9836-e41b249fc01d",
        "_cell_guid": "7dd6850c-7c91-4fe3-ac7c-9208bd6aeba7",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2023-04-16T14:20:09.310415Z",
          "iopub.status.idle": "2023-04-16T14:20:09.310932Z",
          "shell.execute_reply.started": "2023-04-16T14:20:09.310663Z",
          "shell.execute_reply": "2023-04-16T14:20:09.310690Z"
        },
        "trusted": true,
        "id": "XLHhLVKQ7jRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculating final accuracy on test dataset with optimal hyperparameter (alpha)**"
      ],
      "metadata": {
        "id": "1BpCGeWMqvfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# All the lines of code in this cell were taken from Reference [4].\n",
        "\n",
        "alpha = 10000\n",
        "test_pred = predict_alpha(testset, alpha, rotten_word_prob_dict_train, fresh_word_prob_dict_train)\n",
        "\n",
        "lap_test_accuracy = accuracyscore(testset[\"Freshness\"].to_list(), test_pred)\n",
        "print(f'Final Accuracy on Test Dataset after applying Laplace smoothing : {lap_test_accuracy} %')"
      ],
      "metadata": {
        "_uuid": "8adab917-b605-468b-b2b5-aa9a7233d776",
        "_cell_guid": "981f0704-9659-422d-af37-47b5f1ea7b2b",
        "jupyter": {
          "outputs_hidden": false
        },
        "trusted": true,
        "id": "4TfazqiF7jRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}